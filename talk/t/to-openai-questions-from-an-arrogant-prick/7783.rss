<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>To openai: questions from an arrogant prick</title>
    <link>/talk/t/to-openai-questions-from-an-arrogant-prick/7783</link>
    <description>The [arrogant prick being myself](https://what.thedailywtf.com/t/the-incoherent-ramblings-of-the-discojuice-huffing-dude/53070), of course! ;)

I was just talking to my friend about basiux, per his request, and he suggested me again, like everyone I talk to about it, to get in touch with you guys. Of course, I said &quot;already did, and they put me down&quot;:

https://twitter.com/cauerego/status/677200028981702656

After reading your email again, Matt, I must say...

What do you even mean by accomplished?

And did you notice &quot;my mario video&quot; you talked about wasn&#39;t mine?

&lt;details&gt;&lt;summary&gt;I&#39;m improving the way I communicate by the day, and shouting out whatever I&#39;m trying to say while **representing basiux** is really hard. I&#39;m not sure how long you guys took to write that landing page on openAi, it is very well written but... It&#39;s also still too subjective as well. Leaving way too much of a margin for interpretation and a couple of questions...&lt;/summary&gt;

From [openai.com](http://openai.com):

[quote]
OpenAI About
Introducing OpenAI

by Greg Brockman, Ilya Sutskever, and the OpenAI team
December 11, 2015
OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.

Since our research is free from financial obligations, we can better focus on a positive human impact. We believe AI should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible.

The outcome of this venture is uncertain and the work is difficult, but we believe the goal and the structure are right. We hope this is what matters most to the best in the field.

Background

Artificial intelligence has always been a surprising field. In the early days, people thought that solving certain tasks (such as chess) would lead us to discover human-level intelligence algorithms. However, the solution to each task turned out to be much less general than people were hoping (such as doing a search over a huge number of moves).

The past few years have held another flavor of surprise. An AI technique explored for decades, deep learning, started achieving state-of-the-art results in a wide variety of problem domains. In deep learning, rather than hand-code a new algorithm for each problem, you design architectures that can twist themselves into a wide range of algorithms based on the data you feed them.

This approach has yielded outstanding results on pattern recognition problems, such as recognizing objects in images, machine translation, and speech recognition. But we&#39;ve also started to see what it might be like for computers to be creative, to dream, and to experience the world.

Looking forward

AI systems today have impressive but narrow capabilities. It seems that we&#39;ll keep whittling away at their constraints, and in the extreme case they will reach human performance on virtually every intellectual task. It&#39;s hard to fathom how much human-level AI could benefit society, and it&#39;s equally hard to imagine how much it could damage society if built or used incorrectly.

OpenAI

Because of AI&#39;s surprising history, it&#39;s hard to predict when human-level AI might come within reach. When it does, it&#39;ll be important to have a leading research institution which can prioritize a good outcome for all over its own self-interest.

We&#39;re hoping to grow OpenAI into such an institution. As a non-profit, our aim is to build value for everyone rather than shareholders. Researchers will be strongly encouraged to publish their work, whether as papers, blog posts, or code, and our patents (if any) will be shared with the world. We&#39;ll freely collaborate with others across many institutions and expect to work with companies to research and deploy new technologies.

OpenAI&#39;s research director is Ilya Sutskever, one of the world experts in machine learning. Our CTO is Greg Brockman, formerly the CTO of Stripe. The group&#39;s other founding members are world-class research engineers and scientists: Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba. Pieter Abbeel, Yoshua Bengio, Alan Kay, Sergey Levine, and Vishal Sikka are advisors to the group. OpenAI&#39;s co-chairs are Sam Altman and Elon Musk.

Sam, Greg, Elon, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research are donating to support OpenAI. In total, these funders have committed $1 billion, although we expect to only spend a tiny fraction of this in the next few years.

You can follow us on Twitter at @open_ai or email us at info@openai.com.
[/quote]
&lt;/details&gt;

So, let me put this in another way: **I&#39;m not sure I even want to join you anymore**.

- Why aren&#39;t you going full open about it? Wasn&#39;t it supposed to be open? Well, you&#39;re around for at about 1 month now and you&#39;re probably together for longer than that and you released only 2 static pages up to now.

- Would you say we need to be able to **control** the Ai in any format? I personally think that&#39;s the most dangerous aspect we could strive for in an Ai and the letter is far from clear in this aspect. ASi must be set free and we must fear nothing from it or else, that&#39;s where the only danger may lie. Although, the most dangerous aspect of it is losing precious time.

Now, I&#39;m pretty positive that with all your team&#39;s technical background and accomplishments you&#39;ll still have some hard time understanding what I&#39;m trying to say here. Mostly because, well, I&#39;m terrible at making myself clear. I have always been.

[But also because I&#39;m quite an unspoken and very self accomplished genius](/talk/t/to-sgu-openai-the-church-of-tech-and-neural-networks/7778/1).  I&#39;m freaking intelligent and smart and stupid and idiot all at once. And you can eat me, for all I care. ;P

Please, by all means, do answer those in a public place of your convenience. I appreciate if you can also link me there, but I&#39;ll probably be notified by it eventually.</description>
    <language>en</language>
    <lastBuildDate>Thu, 31 Dec 2015 10:30:53 +0000</lastBuildDate>
    <category>public emails</category>
    <atom:link href="/talk/t/to-openai-questions-from-an-arrogant-prick/7783.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>To openai: questions from an arrogant prick</title>
        <dc:creator><![CDATA[@cregox Caue Rego]]></dc:creator>
        <description><![CDATA[
          <p><a href="/talk/u/cregox">@cregox</a> wrote:</p>
          <blockquote>
              <p>Yesterday, <a href="https://www.facebook.com/filipe.n.cunha/">talking to my newest close friend</a>, he forced me into realizing something...</p>

<p><a href="/talk/t/a-feedback-for-my-application-at-crossover/7658/14?u=cregox">I had already written somewhere</a> a very short description of what basiux.org is today, something along these lines:</p>

<blockquote><p>basiux.org has the same goal as openai.com with 2 twists: I started it when I was born. And I've been using all my free time since July into building what you can see on the website now (along with all links available).</p></blockquote>

<p>All that is being translated into <strong>the novel</strong>. He told me he was reading some of my blog or something and he thought to himself "fuck, this guy is writing the next Matrix!". Am I? I sure like to think so. <img src="/talk/images/emoji/emoji_one/smiley.png?v=1" title=":smiley:" class="emoji" alt=":smiley:"></p>

<p>Please, <a href="http://blog.cregox.com/2015/12/26/the-next-ai-poca-lips.html">be our judge</a>:</p>

<aside class="onebox whitelistedgeneric">
  <header class="source">
    <a href="http://blog.cregox.com/2015/12/26/the-next-ai-poca-lips.html">
      
      blog.cregox.com
    </a>
  </header>
  <article class="onebox-body">
    

<h3><a href="http://blog.cregox.com/2015/12/26/the-next-ai-poca-lips.html"></a></h3>

<p></p>

  </article>
  <div style="clear: both"></div>
</aside>


<p>Maybe we should rebrand the site <strong>and</strong> <em>even</em> the church...</p>

<blockquote><p><strong>basiux.org has the same goal as openai.com with 1 twist: we're writing a novel</strong> <em>and we may get many dorment artists to join the one already doing it</em>.</p></blockquote>

<p>Or something. I'm terrible with PR (as you can see from this year old pic)! <img src="/talk/images/emoji/emoji_one/smiley.png?v=1" title=":smiley:" class="emoji" alt=":smiley:"></p>

<p><a href="https://soundcloud.com/caue-rego/imagine-basiux"><img src="/talk/uploads/default/original/1X/f9d21aba8c5d576d8c55027b7f1e98fccdc4f457.jpg" width="418" height="500">

<h2>A song starts playing...</h2></a>

</p><iframe width="100%" height="450" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?visual=false&amp;url=https%3A%2F%2Fapi.soundcloud.com%2Fplaylists%2F180743149&amp;show_artwork=true"></iframe>
          </blockquote>
          <p><a href="/talk/t/to-openai-questions-from-an-arrogant-prick/7783/3">Read full topic</a></p>
        ]]></description>
        <link>/talk/t/to-openai-questions-from-an-arrogant-prick/7783/3</link>
        <pubDate>Thu, 31 Dec 2015 08:03:36 +0000</pubDate>
        <guid isPermaLink="false">talk.cregox.com-post-7783-3</guid>
        <source url="/talk/t/to-openai-questions-from-an-arrogant-prick/7783.rss">To openai: questions from an arrogant prick</source>
      </item>
      <item>
        <title>To openai: questions from an arrogant prick</title>
        <dc:creator><![CDATA[@cregox Caue Rego]]></dc:creator>
        <description><![CDATA[
          <p><a href="/talk/u/cregox">@cregox</a> wrote:</p>
          <blockquote>
              <p>Got a very, <a href="https://twitter.com/gdb/status/681227396658286592">very quick</a> <a href="https://quip.com/uJIgAyQbbdhh">reply from Greg, the openai CEO</a>:</p>

<p><aside class="quote"><blockquote>
<p>re: ﻿<a href="https://twitter.com/cauerego/status/681202528810319874">https://twitter.com/cauerego/status/681202528810319874</a>﻿<br>First of all, let me say: there are many different perspectives and approaches towards how to make progress on AI technologies. I am very supportive of there being a variety of groups in this field, and am especially excited about other groups who are similarly focused on building value for the world rather than any one subgroup.</p>
<p>To your points:</p>
<p>&gt; I'm not sure how long you guys took to write that landing page on openAi</p>
<p>Quite some time! I see a draft dating to the beginning of October, but we've been disccussing the ideas contained in it for much longer.</p>
<p>&gt; it is very well written but... It's also still too subjective as well. Leaving way too much of a margin for interpretation and a couple of questions...</p>
<p>Thanks. We don't claim it was a perfect post, but we hope it communicated the gist of what we're trying to do. We've fleshed out a few points in longer articles such as:</p>
<p>- ﻿<a href="http://singularityhub.com/2015/12/20/inside-openai-will-transparency-protect-us-from-artificial-intelligence-run-amok/">http://singularityhub.com/2015/12/20/inside-openai-will-transparency-protect-us-from-artificial-intelligence-run-amok/</a>﻿<br>- ﻿<a href="https://medium.com/backchannel/how-elon-musk-and-y-combinator-plan-to-stop-computers-from-taking-over-17e0e27dd02a">https://medium.com/backchannel/how-elon-musk-and-y-combinator-plan-to-stop-computers-from-taking-over-17e0e27dd02a</a>﻿</p>
<p>But we think that words only go so far, and the actual research we produce will be the only true way to truly communicate to the world what we're doing. So right now our focus is on getting the organization off the ground.</p>
<p>&gt; Why aren't you going full open about it? Wasn't it supposed to be open? Well, you're around for at about 1 month now and you're probably together for longer than that and you released only 2 static pages up to now.</p>
<p>I agree, it's only been been a month! We're focused on the long term, and it'll take us much longer to produce the kind of impactful research results we hope to share with the world.</p>
<p>As Andrej mentions in the SingularityHub article above, our primary focus is producing research that ends up being owned by the world. Our goals and mission are transparent and open from the beginning. That being said, we think that a new research direction is like spark being coaxed into a flame: you need to shelter it and give it some oxygen, but too much attention too early will smother it. So while we expect to produce lots of open-source code, we're definitely not open-sourcing everything from inception.</p>
<p>Said another way, we are focused primarily on producing a positive human impact, and secondarily on tactics such as being open source.</p>
<p>&gt; What do you even mean by accomplished?</p>
<p>We're still learning about our own needs, and so this answer will likely change over time. Right now we're specifically looking for scientists who have had novel results that change the way people approach some field. We're also less actively hiring a few engineers who e.g. have created and scaled products with many users, or built systems to make machine learning teams much more productive.</p>
<p>We think many kinds of people can contribute to progress in AI, and we know that the set of people we're starting with today is just one slice. That'll hopefully change over time.</p>
<p>&gt; Would you say we need to be able to control the Ai in any format? I personally think that's the most dangerous aspect we could strive for in an Ai and the letter is far from clear in this aspect. ASi must be set free and we must fear nothing from it or else, that's where the only danger may lie. Although, the most dangerous aspect of it is losing precious time.</p>
<p>Today, I find it hard to make any definitive statements about what ASI (or even AGI, really) might be like. Many smart people (e.g. MIRI, Nick Bostrom) have been thinking about these questions for a long time, and it's clear that the issues are far more subtle and complex than can be captured in a few sentences. But certainly my personal inclination aligns with what you say above: it seems better to build towards a world where intelligent agents coexist in equality rather than trying to control each other.</p>
<p>I hope that's helpful, and that once we have some results to share, you'll be willing to re-evaluate your opinion of us. In any case, I'm around if you have further questions: ﻿gdb@openai.com﻿.</p>
<p>- Greg Brockman</p>
</blockquote></aside></p>

<p>I evaluate my opinions, points of views and set of beliefs rather quickly and constantly, Greg.</p>

<p>Thanks so much for this and yes, I now am back to the mindset of envying anyone working with you!</p>

<p>Hope I can join your team as soon as you allow me. <img src="/talk/images/emoji/emoji_one/slightly_smiling.png?v=1" title=":slightly_smiling:" class="emoji" alt=":slightly_smiling:"></p>

<p>Do you think we could talk over voice? We would probably get well aligned rather quickly and I think I've got <strong>a lot</strong> to contribute.</p>

<h1>edited after <a href="https://twitter.com/gdb/status/681232114814042112">reply</a>
</h1>

<p>Since you're swamped and open for questions, I just did think in a very important question we'll face and you <strong>probably</strong> are light years ahead of me and maybe every other group out there:</p>

<h2><strong>What would be your engineering approach?</strong></h2>

<p>Unfortunately, I'm not versed into the literature. I haven't even had the chance to dig down pieces of code myself, but... <a>Our current approach</a> would also be along these lines:</p>

<ul>
<li><p>Language independent, although probably and ideally using javascript for easy communication with computers and humans (something pretty much like Mariox).</p></li>
<li><p>Some kind of genetic algorithm, reinforced by just a few different fitnesses.</p></li>
<li><p>Many different graph sets / neural networks to analyze input from different angles (analogous to emotions).</p></li>
<li><p>As stated elsewhere, the subconscious would need to be constantly compressing data (i.e. recognizing patterns)</p></li>
</ul>

<h2>Also...</h2>

<p>I was very glad just now, after reading <a href="http://singularityhub.com/2015/12/20/inside-openai-will-transparency-protect-us-from-artificial-intelligence-run-amok/">the first link there</a>. We are indeed completely aligned and I kinda envy your ability with words, as a team. Very well placed answers, great interview! <img src="/talk/images/emoji/emoji_one/slightly_smiling.png?v=1" title=":slightly_smiling:" class="emoji" alt=":slightly_smiling:"></p>

<p>It's really tough bringing these ideas to so many questions that are so unaware of what Ai even is today. Just by doing that alone you're kinda already helping us as well. We can always point to your research! <img src="/talk/images/emoji/emoji_one/stuck_out_tongue_winking_eye.png?v=1" title=":stuck_out_tongue_winking_eye:" class="emoji" alt=":stuck_out_tongue_winking_eye:"></p>

<h1>Lul wot!</h1>

<p>I just realized I had already skimmed the second link, <a href="https://medium.com/@cauerego/i-m-really-thrilled-to-see-someone-as-smart-as-musk-in-fact-the-person-i-believed-in-the-most-to-bdd8431e1d14#.f5zpqmobr">and had already even replied to it some time ago</a>! <img src="/talk/images/emoji/emoji_one/smiley.png?v=1" title=":smiley:" class="emoji" alt=":smiley:"></p>
          </blockquote>
          <p><a href="/talk/t/to-openai-questions-from-an-arrogant-prick/7783/2">Read full topic</a></p>
        ]]></description>
        <link>/talk/t/to-openai-questions-from-an-arrogant-prick/7783/2</link>
        <pubDate>Sun, 27 Dec 2015 21:43:56 +0000</pubDate>
        <guid isPermaLink="false">talk.cregox.com-post-7783-2</guid>
        <source url="/talk/t/to-openai-questions-from-an-arrogant-prick/7783.rss">To openai: questions from an arrogant prick</source>
      </item>
      <item>
        <title>To openai: questions from an arrogant prick</title>
        <dc:creator><![CDATA[@cregox Caue Rego]]></dc:creator>
        <description><![CDATA[
          <p><a href="/talk/u/cregox">@cregox</a> wrote:</p>
          <blockquote>
              <p>The <a href="https://what.thedailywtf.com/t/the-incoherent-ramblings-of-the-discojuice-huffing-dude/53070">arrogant prick being myself</a>, of course! <img src="/talk/images/emoji/emoji_one/wink.png?v=1" title=":wink:" class="emoji" alt=":wink:"></p>

<p>I was just talking to my friend about basiux, per his request, and he suggested me again, like everyone I talk to about it, to get in touch with you guys. Of course, I said "already did, and they put me down":</p>

<aside class="onebox twitterstatus">
  <header class="source">
    <a href="https://twitter.com/cauerego/status/677200028981702656">
      
      twitter.com
    </a>
  </header>
  <article class="onebox-body">
    <img src="https://pbs.twimg.com/profile_images/518869398304468992/GioPePMd_normal.jpeg" class="thumbnail" width="48" height="48">
<h4>
  <a href="https://twitter.com/cauerego/status/677200028981702656">
    Caue C M Rego (cauerego)
  </a>
</h4>

<div class="tweet">Just got a great feedback from <a href="https://twitter.com/MattKrisiloff" target="_blank">@MattKrisiloff</a> at <a href="https://twitter.com/open_ai" target="_blank">@open_ai</a> - small team of 9 hiring only exceptionally experienced engineers / ai researchers</div>

<div class="date">
  <a href="https://twitter.com/cauerego/status/677200028981702656" target="_blank"> 4:54 PM - 16 Dec 2015</a>
</div>

  </article>
  <div style="clear: both"></div>
</aside>


<p>After reading your email again, Matt, I must say...</p>

<p>What do you even mean by accomplished?</p>

<p>And did you notice "my mario video" you talked about wasn't mine?</p>

<p><details><summary>I'm improving the way I communicate by the day, and shouting out whatever I'm trying to say while <strong>representing basiux</strong> is really hard. I'm not sure how long you guys took to write that landing page on openAi, it is very well written but... It's also still too subjective as well. Leaving way too much of a margin for interpretation and a couple of questions...</summary>

<p>From <a href="http://openai.com">openai.com</a>:</p>

<p><aside class="quote"><blockquote>
<p>OpenAI About<br>Introducing OpenAI</p>
<p>by Greg Brockman, Ilya Sutskever, and the OpenAI team<br>December 11, 2015<br>OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return.</p>
<p>Since our research is free from financial obligations, we can better focus on a positive human impact. We believe AI should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible.</p>
<p>The outcome of this venture is uncertain and the work is difficult, but we believe the goal and the structure are right. We hope this is what matters most to the best in the field.</p>
<p>Background</p>
<p>Artificial intelligence has always been a surprising field. In the early days, people thought that solving certain tasks (such as chess) would lead us to discover human-level intelligence algorithms. However, the solution to each task turned out to be much less general than people were hoping (such as doing a search over a huge number of moves).</p>
<p>The past few years have held another flavor of surprise. An AI technique explored for decades, deep learning, started achieving state-of-the-art results in a wide variety of problem domains. In deep learning, rather than hand-code a new algorithm for each problem, you design architectures that can twist themselves into a wide range of algorithms based on the data you feed them.</p>
<p>This approach has yielded outstanding results on pattern recognition problems, such as recognizing objects in images, machine translation, and speech recognition. But we've also started to see what it might be like for computers to be creative, to dream, and to experience the world.</p>
<p>Looking forward</p>
<p>AI systems today have impressive but narrow capabilities. It seems that we'll keep whittling away at their constraints, and in the extreme case they will reach human performance on virtually every intellectual task. It's hard to fathom how much human-level AI could benefit society, and it's equally hard to imagine how much it could damage society if built or used incorrectly.</p>
<p>OpenAI</p>
<p>Because of AI's surprising history, it's hard to predict when human-level AI might come within reach. When it does, it'll be important to have a leading research institution which can prioritize a good outcome for all over its own self-interest.</p>
<p>We're hoping to grow OpenAI into such an institution. As a non-profit, our aim is to build value for everyone rather than shareholders. Researchers will be strongly encouraged to publish their work, whether as papers, blog posts, or code, and our patents (if any) will be shared with the world. We'll freely collaborate with others across many institutions and expect to work with companies to research and deploy new technologies.</p>
<p>OpenAI's research director is Ilya Sutskever, one of the world experts in machine learning. Our CTO is Greg Brockman, formerly the CTO of Stripe. The group's other founding members are world-class research engineers and scientists: Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba. Pieter Abbeel, Yoshua Bengio, Alan Kay, Sergey Levine, and Vishal Sikka are advisors to the group. OpenAI's co-chairs are Sam Altman and Elon Musk.</p>
<p>Sam, Greg, Elon, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research are donating to support OpenAI. In total, these funders have committed $1 billion, although we expect to only spend a tiny fraction of this in the next few years.</p>
<p>You can follow us on Twitter at <span class="mention">@open_ai</span> or email us at info@openai.com.</p>
</blockquote></aside></p>

<p></p></details></p>

<p>So, let me put this in another way: <strong>I'm not sure I even want to join you anymore</strong>.</p>

<ul>
<li><p>Why aren't you going full open about it? Wasn't it supposed to be open? Well, you're around for at about 1 month now and you're probably together for longer than that and you released only 2 static pages up to now.</p></li>
<li><p>Would you say we need to be able to <strong>control</strong> the Ai in any format? I personally think that's the most dangerous aspect we could strive for in an Ai and the letter is far from clear in this aspect. ASi must be set free and we must fear nothing from it or else, that's where the only danger may lie. Although, the most dangerous aspect of it is losing precious time.</p></li>
</ul>

<p>Now, I'm pretty positive that with all your team's technical background and accomplishments you'll still have some hard time understanding what I'm trying to say here. Mostly because, well, I'm terrible at making myself clear. I have always been.</p>

<p><a href="/talk/t/to-sgu-openai-the-church-of-tech-and-neural-networks/7778/1">But also because I'm quite an unspoken and very self accomplished genius</a>.  I'm freaking intelligent and smart and stupid and idiot all at once. And you can eat me, for all I care. <img src="/talk/images/emoji/emoji_one/stuck_out_tongue_winking_eye.png?v=1" title=":stuck_out_tongue_winking_eye:" class="emoji" alt=":stuck_out_tongue_winking_eye:"></p>

<p>Please, by all means, do answer those in a public place of your convenience. I appreciate if you can also link me there, but I'll probably be notified by it eventually.</p>
          </blockquote>
          <p><a href="/talk/t/to-openai-questions-from-an-arrogant-prick/7783/1">Read full topic</a></p>
        ]]></description>
        <link>/talk/t/to-openai-questions-from-an-arrogant-prick/7783/1</link>
        <pubDate>Sun, 27 Dec 2015 19:50:39 +0000</pubDate>
        <guid isPermaLink="false">talk.cregox.com-post-7783-1</guid>
        <source url="/talk/t/to-openai-questions-from-an-arrogant-prick/7783.rss">To openai: questions from an arrogant prick</source>
      </item>
  </channel>
</rss>
